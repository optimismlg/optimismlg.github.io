{"meta":{"title":"leguan's notes","subtitle":null,"description":"生如夏花之绚烂 死如秋叶之静美","author":"乐冠","url":"http://yoursite.com"},"pages":[{"title":"分类","date":"2017-01-16T05:40:30.000Z","updated":"2017-01-16T05:45:52.000Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"概率论","slug":"PRML-notes-Ch0102-Probability-Theory","date":"2017-01-16T11:26:24.000Z","updated":"2017-01-16T11:51:09.000Z","comments":true,"path":"2017/01/16/PRML-notes-Ch0102-Probability-Theory/","link":"","permalink":"http://yoursite.com/2017/01/16/PRML-notes-Ch0102-Probability-Theory/","excerpt":"","text":"加法法则：$$p(X)=\\sum_{Y}p(X,Y)$$乘法法则：$$p(X,Y)=p(Y|X)P(X)$$其中，$p(X,Y)$为联合概率，$p(Y|X)$为条件概率 由乘法法则可得贝叶斯公式：$$p(Y|X)=\\frac{p(X|Y)P(Y)}{p(X)}$$再由加法法则，贝叶斯公式的分母可以写成$$p(X)=\\sum_{Y}p(X,Y)=\\sum_{Y}p(X|Y)P(Y)$$如果$p(X,Y)=p(X)p(Y)$，那么$X,Y$是独立的。 1、概率密度2、期望和方差3、贝叶斯概率4、高斯分布5、重新理解曲线拟合6、贝叶斯曲线拟合","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[]},{"title":"PRML读书笔记-ch01-01","slug":"PRML-notes-Ch0101-Polynomial-Curve-Fitting","date":"2017-01-15T13:48:23.000Z","updated":"2017-01-16T08:16:28.000Z","comments":true,"path":"2017/01/15/PRML-notes-Ch0101-Polynomial-Curve-Fitting/","link":"","permalink":"http://yoursite.com/2017/01/15/PRML-notes-Ch0101-Polynomial-Curve-Fitting/","excerpt":"","text":"假设我们有N组(x,t)训练集，记$\\mathbf{x}=(x_{1},x_{2},\\dots,x_{n})^{T}$，$\\mathbf{t}=(t_{1},t_{2},\\dots,t_{n})^{T}$，我们的目标是利用这个训练集，预测对新输入变量$\\hat{x}$的目标值$\\hat{t}$。 考虑使用多项式拟合$$y(x,\\mathbf{w})=w_{0}+w_{1}x+w_{2}x^{2}+\\dots+w_{M}x^{M}=\\sum_{j=0}^{M}w_{j}x^{j} \\tag{1}$$ 这些多项式的系数可以通过我们的数据拟合得到，即在训练集上最小化一个关于$y(x,\\mathbf{w})$和 $t$ 的损失函数。常见的一个损失函数是平方误差和，定义为：$$E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^{N}{y(x,\\mathbf{w})-t_{n}}^{2} \\tag{2}$$ 为了控制过拟合现象，可以采用正则化（regulariztion）方法，增加一个惩罚项，防止系数达到偏大的值。一个最常用的正则项是平方正则项，即控制所有参数的平方和大小，$$\\tilde E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^{N}{y(x_{n},\\mathbf{w})-t_{n}}^{2}+\\frac{\\lambda}{2}\\lVert\\mathbf{w}\\lVert^{2} \\tag{3}$$ 其中$\\lVert\\mathbf{w}\\lVert^{2}=w_{0}^{2}+w_{1}^{2}+\\dots+w_{m}^{2}$，$\\lambda$是控制正则项和误差项的相对重要性。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2017-01-15T08:39:57.000Z","updated":"2017-01-15T08:39:57.000Z","comments":true,"path":"2017/01/15/hello-world/","link":"","permalink":"http://yoursite.com/2017/01/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}