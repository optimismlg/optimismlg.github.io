{"meta":{"title":"leguan's notes","subtitle":null,"description":"生如夏花之绚烂 死如秋叶之静美","author":"乐冠","url":"http://yoursite.com"},"pages":[{"title":"分类","date":"2017-01-16T05:40:30.000Z","updated":"2017-01-16T05:45:52.000Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"PRML读书笔记-ch0102-概率论","slug":"PRML-notes-Ch0102-Probability-Theory","date":"2017-01-16T11:26:24.000Z","updated":"2017-01-21T05:22:07.000Z","comments":true,"path":"2017/01/16/PRML-notes-Ch0102-Probability-Theory/","link":"","permalink":"http://yoursite.com/2017/01/16/PRML-notes-Ch0102-Probability-Theory/","excerpt":"","text":"概率论加法法则：$$p(X)=\\sum_{Y}p(X,Y)$$乘法法则：$$p(X,Y)=p(Y|X)P(X)$$其中，$p(X,Y)$为联合概率，$p(Y|X)$为条件概率 由乘法法则可得贝叶斯公式：$$p(Y|X)=\\frac{p(X|Y)P(Y)}{p(X)}$$再由加法法则，贝叶斯公式的分母可以写成$$p(X)=\\sum_{Y}p(X,Y)=\\sum_{Y}p(X|Y)P(Y)$$如果$p(X,Y)=p(X)p(Y)$，那么$X,Y$是独立的。 概率密度概率密度函数对于实数$x$，概率密度$p(x)$定义为：当$\\delta x \\rightarrow 0$时，变量$x$落在区间$(x,x+\\delta x)$范围为的概率为$p(x)\\delta x$。$x$落在区间$(a,b)$的概率为： $$p(x \\in (a.b))= \\int_{a}^{b} p(x)dx$$概率密度函数，需要满足以下两个条件：$$p(x) \\ge 0$$$$\\int _{-\\infty}^{\\infty}p(x)dx=1$$ 累计分布函数累计分布函数定义为：$$P(z)=\\int_{-\\infty}^{z}p(x)dx$$满足$P’(x)=p(x)$。 联合概率密度对于多个变量$x_{1},\\dots,x_{D}$（用$\\mathbf x$表示），定义联合概率密度为$p(\\mathbf x)=p(x_{1},\\dots,x_{D})$，满足当$\\mathbf x$落在一个包含$\\mathbf x$的足够小空间$\\delta \\mathbf x$中时，其概率为$p(\\mathbf x)\\delta\\mathbf x$，也需要满足$$p(\\mathbf x) \\ge 0$$$$\\int _{-\\infty}^{\\infty}p(\\mathbf x)d\\mathbf x=1$$ 期望和方差期望函数$f(x)$在概率密度函数$p(x)$下的均值叫做$f(x)$的期望。离散分布下，定义为：$$\\mathbb{E}[f]=\\sum_{x}p(x)f(x)$$连续分布下，定义为：$$\\mathbb{E}[f]=\\int_p(x)f(x)$$ 条件期望多元函数可以对其中一个参数求期望，例如$\\mathbb{E}_{x}[f(x,y)]$是函数$f(x,y)$在概率密度$f(x)$上的期望。考虑$f(x,y)$在条件分布$p(x|y)$下的条件期望。当$x$是离散变量时，定义为$$\\mathbb{E}_{x}[f(|y)]=\\sum_{x}p(x|y)f(x)$$ 方差$f(x)$的方差定义为$$var[f]=\\mathbb{E}[(f(x)-\\mathbb{E}[f(x)])^2]$$平方展开后，可以写为$$var[f]=\\mathbb{E}[f(x^2)]-(\\mathbb{E}f(x))^2$$特别地，考虑$x$本身的方差$$var[x]=\\mathbb{E}[x^2]-\\mathbb{E}[x]^2$$ 协方差对于两个随机变量$x,y$，协方差定义为：$$\\begin{split}cov[x,y]&amp;=\\mathbb{E}_{x,y}[{x-\\mathbb{E}[x]}{y-\\mathbb{E}[y]}] \\\\&amp;=\\mathbb{E}_{x,y}[xy]-\\mathbb{E}[x]\\mathbb{E}[y]\\end{split}$$当变量$x,y$独立时，协方差为0. 协方差矩阵对于两个随机向量$\\mathbf{x},\\mathbf{y}$，其协方差为矩阵：$$\\begin{split}cov[\\mathbf{x},\\mathbf{y}]&amp;=\\mathbb{E}_{\\mathbf{x},\\mathbf{y}}[{\\mathbf{x}-\\mathbb{E}[\\mathbf{x}]}{\\mathbf{y}^{T}-\\mathbb{E}[\\mathbf{y}^{T}]}] \\\\&amp;=\\mathbb{E}_{\\mathbf{x},\\mathbf{y}}[\\mathbf{x}\\mathbf{y}^{T}]-\\mathbb{E}[\\mathbf{x}]\\mathbb{E}[\\mathbf{y}^{T}]\\end{split}$$ 贝叶斯概率假设我们有一组模型参数$\\mathbf{w}$，先验概率分布为$p(\\mathbf{w})$，$\\mathcal{D}={t_{1},\\dots,t_{N}}$为一组观测数据，这组数据在$\\mathbf{w}$的条件概率分布为$p(\\mathcal{D}|\\mathbf{w})$。贝叶斯公式告诉我们：$$p(\\mathbf{w}|\\mathcal{D})=\\frac{p(\\mathcal{D}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathcal{D})}$$ 似然函数$p(\\mathcal{D}|\\mathbf{w})$可以看作是给定观测数据$\\mathcal{D}$的情况下关于参数$\\mathbf{w}$的一个函数，叫做似然函数(likelihood function)，它反映了给定参数向量$\\mathbf{w}$的情况下，生成这组观测数据的可能性。 上面的贝叶斯也可以写为$$posterior\\varpropto likelihood \\times prior$$这三个量都是$\\mathbf{w}$的函数。 在贝叶斯学派和频率学派眼中，似然函数$p(\\mathcal{D}|\\mathbf{w})$扮演了重要的角色，但是两者的认知各异。 频率学派认为，$\\mathbf{w}$是一个固定参数，由某些估计只来决定，误差的计算要考虑数据$\\mathcal{D}$的分布。 贝叶斯学派认为，数据集$\\mathcal{D}$是固定的，参数$\\mathbf{w}$的不确定性可用$\\mathbf{w}$的概率分布来表示。 频率估计：最大似然最常用的频率估计量是最大似然(maximum likelihood)，选择合适的$\\mathbf{w}$以最大化似然函数。在机器学习的文献中，似然函数的负对数叫做损失函数(error function)，因为负对数函数是单调递减函数，因此最大似然相当于最小化损失函数。 贝叶斯估计贝叶斯估计的一个重要观点是引入先验知识，根据后验概率决定参数$\\mathbf{w}$。 高斯分布高斯分布，又称为正态分布，定义为：$$\\mathcal{N}(x|\\mu,\\sigma^{2})=\\frac{1}{(2\\pi\\sigma^{2})^{1/2}}exp\\lbrace-\\frac{1}{2\\sigma^{2}}(x-\\mu)^2\\rbrace$$其中$\\mu$为均值，$\\sigma^2$为方差，方差的平方根$\\sigma$为标准差。 多维高斯分布对于$D$维的向量$\\mathbf{x}$，高斯分布定义为：$$\\mathcal{N}(x|\\mu,\\Sigma)=\\frac{1}{(2\\pi)^{D/2}}\\frac{1}{|\\Sigma|^{1/2}}exp\\lbrace-\\frac{1}{2}(\\mathbf{x}-\\mu)^{T}\\Sigma^{-1}(\\mathbf{x}-\\mu)\\rbrace$$其中，$D$维的向量$\\mu$是均值，$D\\times D$矩阵$\\Sigma$是方差，$|\\Sigma|$是其行列式。 最大似然估计假设我们有$N$个对$x$的观测数据，记为$\\mathbf{x}=(x_1,\\dots,x_N)^T$，这些数据是独立同分布(independent and identically distributed, i.i.d.)的，服从均值为$\\mu$，方差为$\\sigma^2$的高斯分布，则给定$\\mu$和$\\sigma^2$的情况下，概率密度为：$$p(\\mathbf{x}|\\mu,\\sigma^{2})=\\prod_{n=1}^{N}\\mathcal{N}(x_n|\\mu,\\sigma^2)$$当以上公式看作是关于$\\mu$和$\\sigma$的函数时，即为似然函数。为了确定未知参数，需要求解最大似然函数问题。由于对数函数是单调递增的，因此上式两边可取对数，得到$$\\ln p(\\mathbf{x}|\\mu,\\sigma^{2})=-\\frac{1}{2\\sigma^2}\\sum_{n=1}^{N}(x_N-\\mu)^2-\\frac{N}{2}\\ln \\sigma^2-\\frac{N}{2}\\ln (2\\pi)$$对$\\mu$最大化，得到最大似然解：$$\\mu_{ML}=\\frac{1}{N}\\sum_{n=1}^{N}x_n$$对$\\sigma^2$最大化，得到最大似然解：$$\\sigma_{ML}^2=\\frac{1}{N}\\sum_{n=1}^{N}(x_n-\\mu_{ML})^2$$但是这个解不是无偏的，可以计算期望$$\\mathbb{E}[\\mu_{ML}]=\\mu$$$$\\mathbb{E}[\\sigma_{ML}^2]=(\\frac{N-1}{N})\\sigma^2$$因此，方差的无偏估计为：$$\\tilde{\\sigma}^2=\\frac{N}{N-1}\\sigma_{ML}^2=\\frac{1}{N-1}\\sum_{n=1}^{N}(x_n-\\mu_{ML})^2$$ 重新理解曲线拟合重新考虑曲线拟合问题，设输入为$x=(x_1,\\dots,x_N)^T$，对应的目标值为$t=(t_1,\\dots,t_N)^T$，可以把$t$看作是以$y(x,\\mathbf{w})$为均值的高斯分布：$$p(t|x,\\mathbf{w},\\beta)=\\mathcal{N}(t|y(x,\\mathbf{w}),\\beta^{-1})$$ 最大似然我们可以使用最大似然方法从训练数据${\\mathbf{x},\\mathbf{t}}$中求解参数$\\mathbf{w}$和$\\beta$，设训练集数据是独立同分布的，似然函数为：$$p(\\mathbf{t}|\\mathbf{x},\\mathbf{w},\\beta)=\\prod_{n=1}^{N}\\mathcal{N}(t_n|y(x_n,w),\\beta^{-1})$$两边去对数有$$\\ln p(\\mathbf{t}|\\mathbf{x},\\mathbf{w},\\beta)=-\\frac{\\beta}{2}\\sum_{n=1}^{N}\\lbrace y(x_n,\\mathbf{w})\\rbrace^2+\\frac{N}{2}\\ln \\beta-\\frac{N}{2}\\ln (2\\pi)$$设最大似然解为$\\mathbf{w}_{ML}$，最大对数似然的问题等价为$$\\min \\frac{1}{2}\\sum_{n=1}^{N}\\lbrace y(x_n,\\mathbf{w})\\rbrace^2$$即为最小化平方误差和。再对精度$\\beta$求最大似然，有$$\\frac{1}{\\beta_{ML}}=\\frac{1}{N}\\sum_{n=1}^{N}\\lbrace y(x_n,\\mathbf{w}_{ML})-t_n\\rbrace^2$$因此，基于以上最大似然解，对于一个新的输入$x$，其输出$t$满足$$p(t|x,\\mathbf{w}_{ML},\\beta_{ML})=\\mathcal{N}(t|y(x,\\mathbf{w}_{ML}),\\beta_{ML}^{-1})$$ 最大后验假设系数$\\mathbf{w}$有一个先验知识$M+1$维多项式（加上常数项），$\\alpha$为控制参数，有$$p(\\mathbf{w}|\\alpha)=\\mathcal{N}(\\mathbf{w}|0,\\alpha^{-1}\\mathbf{I})=(\\frac{\\alpha}{2\\pi})^{(M+1)/2}exp\\lbrace-\\frac{\\alpha}{2}\\mathbf{w}^T\\mathbf{w}\\rbrace$$由贝叶斯公式，后验概率正比于先验概率和似然函数的乘积：$$p(\\mathbf{w}|\\mathbf{x},\\mathbf{t},\\alpha,\\beta)\\varpropto p(\\mathbf{w}|\\mathbf{x},\\mathbf{t},w,\\beta)p(w|\\alpha)$$我们可以通过最大化后验概率(maximum posterior, MAP)来确定参数$\\mathbf{w}$的值，对上式求对数，去除跟$\\mathbf{w}$无关项，得到$$\\max \\frac{\\beta}{2}\\sum_{n=1}^{N}\\lbrace y(x_n,\\mathbf{w})\\rbrace^2+\\frac{\\alpha}{2}\\mathbf{w}^T\\mathbf{w}$$因此，MAP的结果等价于均方误差加上二次正则化，其中正则参数 $\\lambda=\\alpha/\\beta$ 贝叶斯曲线拟合虽然在MAP中我们引入了先验分布，但是本质上它是单点估计。一个完全的贝叶斯估计要求对$\\mathbf{w}$的所有值进行积分。对于多项式拟合问题，给定训练集$\\mathbf{x}$和$\\mathbf{t}$，对于一个新的测试样例$x$，目标值为$t$，考虑分布$p(t|x,\\mathbf{x},\\mathbf{t})$：$$p(t|x,\\mathbf{x},\\mathbf{t})=\\int p(t|x,\\mathbf{w})p(\\mathbf{w}|\\mathbf{x},\\mathbf{t})dw$$其中$p(t|x,\\mathbf{w})$是给定的高斯分布，$p(\\mathbf{w}|\\mathbf{x},\\mathbf{t})$是训练集的后验概率（高斯分布），因此上式也是高斯分布，可以写成$$p(t|x,\\mathbf{x},\\mathbf{t})=\\mathcal{N}(t|m(x)),s^2(x))$$","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[]},{"title":"PRML读书笔记-ch0101-多项式拟合","slug":"PRML-notes-Ch0101-Polynomial-Curve-Fitting","date":"2017-01-15T13:48:23.000Z","updated":"2017-01-21T05:23:47.000Z","comments":true,"path":"2017/01/15/PRML-notes-Ch0101-Polynomial-Curve-Fitting/","link":"","permalink":"http://yoursite.com/2017/01/15/PRML-notes-Ch0101-Polynomial-Curve-Fitting/","excerpt":"","text":"多项式拟合假设我们有N组(x,t)训练集，记$\\mathbf{x}=(x_{1},x_{2},\\dots,x_{n})^{T}$，$\\mathbf{t}=(t_{1},t_{2},\\dots,t_{n})^{T}$，我们的目标是利用这个训练集，预测对新输入变量$\\hat{x}$的目标值$\\hat{t}$。 考虑使用多项式拟合$$y(x,\\mathbf{w})=w_{0}+w_{1}x+w_{2}x^{2}+\\dots+w_{M}x^{M}=\\sum_{j=0}^{M}w_{j}x^{j} \\tag{1}$$ 这些多项式的系数可以通过我们的数据拟合得到，即在训练集上最小化一个关于$y(x,\\mathbf{w})$和 $t$ 的损失函数。常见的一个损失函数是平方误差和，定义为：$$E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^{N}{y(x,\\mathbf{w})-t_{n}}^{2} \\tag{2}$$ 为了控制过拟合现象，可以采用正则化（regulariztion）方法，增加一个惩罚项，防止系数达到偏大的值。一个最常用的正则项是平方正则项，即控制所有参数的平方和大小，$$\\tilde E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^{N}{y(x_{n},\\mathbf{w})-t_{n}}^{2}+\\frac{\\lambda}{2}\\lVert\\mathbf{w}\\lVert^{2} \\tag{3}$$ 其中$\\lVert\\mathbf{w}\\lVert^{2}=w_{0}^{2}+w_{1}^{2}+\\dots+w_{m}^{2}$，$\\lambda$是控制正则项和误差项的相对重要性。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2017-01-15T08:39:57.000Z","updated":"2017-01-15T08:39:57.000Z","comments":true,"path":"2017/01/15/hello-world/","link":"","permalink":"http://yoursite.com/2017/01/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}